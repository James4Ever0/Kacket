{
    "summary": "The given code defines a Lexer class for parsing input text in the Kacket programming language, recognizing tokens such as comments and booleans. It reads characters, identifies tokens (numbers or punctuation), lexes various types of tokens, handles string starts and escapes, maintains a token buffer, and implements functions for checking identifier starts and characters to parse identifiers.",
    "details": [
        {
            "comment": "This code defines a Lexer class for parsing input text using a BufferedReader. It maintains a tokenBuffer to store tokens and tracks lineNum and columnNum for error reporting. The lex() method reads characters from the reader, keeps track of line numbers and column counts, and adds tokens to the buffer until reaching the maximum BUFFER_SIZE or EOF is encountered.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":0-41",
            "content": "package com.github.std.kacket.parse\nimport org.apache.commons.lang3.CharUtils.isAsciiPrintable\nimport java.io.BufferedReader\nimport java.io.Reader\nimport java.lang.StringBuilder\nimport java.util.LinkedList\nconst val BUFFER_SIZE = 50\nclass Lexer(\n    input: Reader,\n    private var lineNum: Int = 1,\n    private var columnNum: Int = 1\n) {\n    private val reader = BufferedReader(input)\n    private val tokenBuffer = LinkedList<Token>()\n    private var read = reader.read()\n    private fun close() {\n        tokenBuffer.add(EOF(lineNum, columnNum))\n        reader.close()\n    }\n    private fun lex() {\n        var tokenCount = 0\n        while (tokenCount <= BUFFER_SIZE) {\n            if (read == -1) {\n                close()\n                return\n            }\n            val char = read.toChar()\n            val (readNext, count) = when {\n                char == '\\n' -> {\n                    columnNum = 1\n                    lineNum++\n                    reader.read() to 0\n                }\n                char.isWhitespace() -> {"
        },
        {
            "comment": "This code is a part of a lexer, responsible for identifying tokens in the input stream. It uses a series of if-else statements to determine the type of token based on the current character and calls corresponding lexing functions accordingly. The 'lexComment', 'lexIdentifier', 'lexChar', 'lexBool', 'lexString', 'lexNumber', and 'lexPunctuation' functions are used to handle different types of tokens, while 'tokenCount' keeps track of the number of tokens encountered.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":42-82",
            "content": "                    reader.read() to 1\n                }\n                char == ';' -> {\n                    lexComment()\n                }\n                isIdentifierStart(char) -> {\n                    tokenCount++\n                    lexIdentifier(char)\n                }\n                isCharStart(char) -> {\n                    tokenCount++\n                    lexChar()\n                }\n                isBoolStart(char) -> {\n                    tokenCount++\n                    lexBool()\n                }\n                isStringStart(char) -> {\n                    tokenCount++\n                    lexString()\n                }\n                isNumberStart(char) -> {\n                    tokenCount++\n                    lexNumber(char)\n                }\n                isSymbolStart(char) -> {\n                    tokenCount++\n                    lexSymbol()\n                }\n                // should be after isSymbolStart\n                isPunctuation(char) -> {\n                    tokenCount++\n                    lexPunctuation(char)"
        },
        {
            "comment": "This code snippet is part of a lexer in a programming language called Kacket. The lexer reads input from a reader, identifies tokens such as comments and booleans, and returns them along with the number of characters consumed. The `lexComment` function recognizes and skips lines starting with '#', while `lexBool` identifies true/false literals. The `isSymbolChar` function checks if a character is a valid symbol for further tokenization. Finally, `isBoolStart` checks if a given character is the start of a boolean literal.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":83-123",
            "content": "                }\n                else -> {\n                    throw LexError(\"Unknown Token at ($lineNum, $columnNum)\")\n                }\n            }\n            read = readNext\n            columnNum += count\n        }\n    }\n    private fun lexComment(): Pair<Int, Int> {\n        var read = reader.read()\n        while (read != -1 && read.toChar() != '\\n') {\n            read = reader.read()\n        }\n        return read to 0\n    }\n    private fun lexBool(): Pair<Int, Int> {\n        val read = reader.read()\n        val value = read.toChar() == 't'\n        tokenBuffer.add(Bool(lineNum, columnNum, value))\n        return reader.read() to 1\n    }\n    private fun isBoolStart(char: Char): Boolean {\n        if (char == '#') {\n            reader.mark(1)\n            val next = reader.read().toChar()\n            if (next == 'f' || next == 't') {\n                reader.reset()\n                return true\n            }\n            reader.reset()\n            return false\n        }\n        return false\n    }\n    private fun isSymbolChar(char: Char): Boolean ="
        },
        {
            "comment": "The code defines a lexer for parsing symbols and numbers in a stream of characters. The `lexSymbol()` function reads characters until it encounters a non-symbol character, appending them to a StringBuilder and counting the number of characters read. If no symbol characters are found, a LexError is thrown. The `isSymbolStart()` function checks if a given character is the start of a single-quoted symbol, and the `lexNumber(first: Char)` function reads characters until it encounters a non-digit character, appending them to a StringBuilder and counting the number of characters read.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":124-158",
            "content": "        !isPunctuation(char) && !char.isWhitespace() && isAsciiPrintable(char)\n    private fun lexSymbol(): Pair<Int, Int> {\n        var read = reader.read()\n        val builder = StringBuilder()\n        var count = 0\n        while (read != -1 && isSymbolChar(read.toChar())) {\n            count++\n            builder.append(read.toChar().toString())\n            read = reader.read()\n        }\n        if (count == 0) {\n            throw LexError(\"Bad Token at ($lineNum, $columnNum)\")\n        }\n        tokenBuffer.add(Symbol(lineNum, columnNum, builder.toString()))\n        return read to count\n    }\n    private fun isSymbolStart(first: Char): Boolean {\n        reader.mark(1)\n        val next = reader.read().toChar()\n        reader.reset()\n        if (first == '\\'' && isSymbolChar(next)) {\n            return true\n        }\n        return false\n    }\n    // (read, count)\n    private fun lexNumber(first: Char): Pair<Int, Int> {\n        var count = 0\n        var read = first.code\n        val builder = StringBuilder()\n        while (read != -1 && read.toChar().isDigit()) {"
        },
        {
            "comment": "This code reads characters from a reader, appends them to a builder if they're not punctuation or digits, and adds the resulting token (number or punctuation) to the token buffer. The isPunctuation, isNumberStart, and isParenthesis helper functions are used for identifying different types of tokens.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":159-189",
            "content": "            count++\n            builder.append(read.toChar().toString())\n            read = reader.read()\n        }\n        if (read.toChar() == '.') {\n            count++\n            builder.append(\".\")\n            read = reader.read()\n        }\n        while (read.toChar().isDigit()) {\n            count++\n            builder.append(read.toChar().toString())\n            read = reader.read()\n        }\n        tokenBuffer.add(Num(lineNum, columnNum, builder.toString()))\n        return read to count\n    }\n    private fun isPunctuation(char: Char): Boolean =\n        char == '\\'' ||\n                char == '#' ||\n                char == '\"' ||\n                isParenthesis(char)\n    private fun isNumberStart(char: Char): Boolean = char.isDigit()\n    private fun isParenthesis(char: Char): Boolean =\n        char == '(' || char == ')' || char == '[' || char == ']'\n    private fun lexPunctuation(first: Char): Pair<Int, Int> {\n        tokenBuffer.add(Punctuation(first, lineNum, columnNum))\n        return reader.read() to 1"
        },
        {
            "comment": "This code defines various functions for lexing different types of tokens (strings, characters) and includes checks for string and character starts. It reads input from a reader, maintains a token buffer to store parsed data, and handles potential escapes in strings.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":190-228",
            "content": "    }\n    private fun lexString(): Pair<Int, Int> {\n        // TODO: escape characters\n        var read = reader.read()\n        val builder = StringBuilder()\n        var count = 0\n        while (read != -1 && read.toChar() != '\\\"') {\n            builder.append(read.toChar().toString())\n            read = reader.read()\n            count++\n        }\n        read = reader.read()\n        tokenBuffer.add(Text(lineNum, columnNum, builder.toString()))\n        return read to count + 2\n    }\n    private fun isStringStart(char: Char): Boolean = char == '\\\"'\n    private fun lexChar(): Pair<Int, Int> {\n        val value = reader.read().toChar()\n        tokenBuffer.add(Character(lineNum, columnNum, value))\n        return reader.read() to 3\n    }\n    private fun isCharStart(char: Char): Boolean {\n        if (char == '#') {\n            reader.mark(1)\n            if (reader.read().toChar() == '\\\\') {\n                return true\n            }\n            reader.reset()\n            return false\n        }\n        return false\n    }\n    private fun lexIdentifier(first: Char): Pair<Int, Int> {"
        },
        {
            "comment": "This code is implementing a lexer for parsing identifiers. It defines functions for checking if a character is an identifier start or an identifier character, and uses these functions to read input and add identified tokens to a buffer. The buffer can be used to retrieve the next or peek at the next token in the parsed input.",
            "location": "\"/media/root/Toshiba XG3/works/Kacket/docs/src/src/main/kotlin/com/github/std/kacket/parse/Lexer.kt\":229-265",
            "content": "        fun isIdentifierChar(char: Char): Boolean =\n            !isPunctuation(char) && !char.isWhitespace() && isAsciiPrintable(char)\n        var read = first.code\n        var count = 0\n        val builder = StringBuilder()\n        while (read != 1 && isIdentifierChar(read.toChar())) {\n            count++\n            builder.append(read.toChar())\n            read = reader.read()\n        }\n        tokenBuffer.add(Identifier(builder.toString(), lineNum, columnNum))\n        return read to count\n    }\n    // TODO: check standard\n    private fun isIdentifierStart(char: Char): Boolean =\n        !isPunctuation(char) &&\n                !char.isDigit() &&\n                isAsciiPrintable(char)\n    fun nextToken(): Token {\n        if (tokenBuffer.isEmpty()) {\n            lex()\n        }\n        return tokenBuffer.removeFirst()\n    }\n    fun peekToken(): Token {\n        if (tokenBuffer.isEmpty()) {\n            lex()\n        }\n        return tokenBuffer.peek()\n    }\n}"
        }
    ]
}